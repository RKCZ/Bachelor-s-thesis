\chapter{Description of exploratory use cases} \label{chapter:05}

This chapter describes the initial experiments with the Nengo simulator and the SNN-Toolbox, which were selected as the most appropriate tools for subsequent use in this work. The decision was based on the pieces of information stated about the individual tools in the previous chapters. Both tools aim to use analogue neural networks to train the model and then convert it to the spiking alternative for inference. This approach is more utilisable for practical needs at the moment because other approaches to use SNNs suffer from issues described in chapter \ref{chapter:02} above. Thus, it is complicated to use them for any practical application such as image recognition. However, they are still necessary for research in the area of spiking networks and scientific experiments. Furthermore, the other simulators proved to be quite hard to work with due to inconsistent dependencies or other issues. \par
At the beginning, the Nengo simulator was inspected more thoroughly. It helps to new users with its simple graphical interface, which contains several tutorials and examples. The tutorials focus mainly on an explanation of the NEF and SPA methods created by authors of the Nengo, rather than on SNNs generally. The GUI is split into a script editor and visualisation area, where the objects created at the edited script is visualised in real time. These visualisations help understand the whole course of the simulation of the spiking neural network. \par
The next goal was to execute the Spaun 2.0 model to inspect the capabilities of the Nengo even further. The objective was to simulate the handwritten digit recognition, which is one of the cognitive tasks that Spaun 2.0 supports. Although this use case should be quite straightforward according to the documentation of the Nengo, there appeared a few issues. Firstly, there does not exist any documentation for the model. It means that the only way how to get information about its execution is to correspond with its authors about every detail, for example, to discover that the model is not compatible with recent versions of the Nengo package. The other problem is probably caused by the fact that the Spaun 2.0 model can require more than 26 gigabytes of memory to execute. Even though the model was executed on a cloud platform, which provides such resources, the program still finished the simulation with memory allocation errors.

\section{Using the same pre-trained model for the Nengo and SNN-Toolbox}
The next objective was to assess conversion abilities of both Nengo and SNN-Toolbox on the similar use case. Conversion of a simple neural network model represented by Keras interface was selected as a suitable use case. The model was assembled and trained as an ordinary analogue neural network on an MNIST dataset. It was a convolutional network, which consisted of multiple consecutive convolutional layers, average pooling layer and batch normalization layer. A visualisation of the network architecture is shown in figure \ref{fig:keras_model}. The presented model was configured to use an Adam \cite{kingmaAdamMethod17} optimizer and categorical cross-entropy as a loss function. Trained weights were saved to a filesystem. \par
There was an issue with using the same network model directly because there exist two versions of Keras framework at this time. SNN-TB uses a standalone multi-backend version of Keras, which supports Theano and CNTK toolkits alongside with the TensorFlow backend. However, this version of Keras will not be further developed in the future. The other version of Keras is integrated directly into TensorFlow as its high-level API for neural network development. This version of Keras interface is used in Nengo platform. However, both versions work similarly and the model exported from one version can be loaded into the other without other problems.\par
\begin{figure}[htbp]
    \centering
    \includesvg[inkscapelatex=false, height=0.65\textheight]{images/keras_model}
    \caption{The Keras model of a convolutional network used for classification of the MNIST dataset.}
    \label{fig:keras_model}
\end{figure}
Evaluation of the network with SNN-TB is straightforward. There must be created a configuration file, which contains all necessary parameters to run the \texttt{main} function of the toolbox. The configuration file is written with a few simple utilisation functions of the SNN-TB. Paths to the model and dataset are passed inside the configuration file as well as a specification of the simulator and its parameters, parameters of the simulated spiking neuron cells and requested output plots. The SNN-TB then automatically performs the conversion of the network and evaluates it on the given test samples. There is an option to evaluate the ANN input model so the results can be compared instantly. \par
Some adjustments need to be done to simulate a corresponding spiking network in the Nengo simulator. The input samples must be reformatted to conform with the format which is required by the Nengo simulator. More exactly, there must be added a dimension to the data array to spread the data over time of the simulation. The \texttt{nengo\_dl.Converter} class converts the ANN. Then the simulation is executed the same way as other simulations in Nengo.
