\chapter{Description of exploratory use cases} \label{chap:05}

This chapter describes the initial experiments with the Nengo simulator and the SNN-Toolbox, which were selected as the most appropriate tools for subsequent use in this work. The decision was based on the pieces of information stated about the individual tools in the previous chapters. Both tools make it possible to use analogue neural networks to train the model and then convert it to the corresponding spiking neural network for inference. This approach is more utilisable for practical needs at the moment because other approaches of using SNNs suffer from issues described in \cref{chap:02} above. Thus, it is complicated to use them for any practical application such as image recognition. However, they are still necessary for research in the area of spiking networks and scientific experiments. Furthermore, the other simulators proved to be quite hard to work with, for example, because of unreliable interfaces of their dependencies or other issues. \par
In the beginning, the Nengo simulator was inspected more thoroughly. It helps to new users with its simple graphical interface, which contains several tutorials and examples. The tutorials focus mainly on an explanation of the Neural Engineering Framework and Semantic Pointer Architecture methods introduced by authors of the Nengo simulator, rather than on SNNs generally. The GUI is divided into a script editor and visualisation area, where are visualised the objects created in the script editor in actual time. These visualisations help understand the whole course of the simulation of the spiking neural network. An additional package \texttt{nengo-gui} must be installed to access the graphical environment. The environment is an HTML5-based application, which is accessed through an internet browser. The interactive editor supports Nengo and NengoDL backends for running the simulation. \par
The next goal was to execute the Spaun 2.0 model to inspect the capabilities of the Nengo even further. The objective was to simulate the handwritten digit recognition, which is one of the cognitive tasks that Spaun 2.0 supports. Although this use case should be quite straightforward according to the documentation of the Nengo, there appeared a few issues. Firstly, there does not exist any documentation for the model. It means that the only way how to get information about its execution is to correspond with its authors about every detail, for example, to discover that the model is not compatible with recent versions of the Nengo package. The other problem is probably caused by the fact that the Spaun 2.0 model can require more than 26 gigabytes of memory to execute. Even though the model was executed on a cloud platform, which provides such resources, the program still finished the simulation with memory allocation errors.

\section{Using the same pre-trained model for the Nengo and SNN-Toolbox}
The next objective was to assess conversion abilities of both Nengo and SNN conversion toolbox on a similar use case. Conversion of a simple neural network model represented by Keras interface was selected as a suitable use case. The model was assembled and trained as an ordinary analogue neural network on an MNIST dataset. The model architecture must have been constrained to allow comparison of the two converters because Nengo currently does not support batch normalisation. Although it should fall back to ANN implementation for unsupported layers, it did not work if batch normalisation layers were in the model.\par
There was an issue with using the same network model directly because there exist two versions of Keras framework at this time. SNN-TB uses a standalone multi-backend version of Keras, which supports Theano and CNTK toolkits alongside with the TensorFlow backend. However, this version of Keras will not be further developed in the future. The other version of Keras is integrated directly into TensorFlow as its high-level API for neural network development. This version of Keras interface is used in Nengo platform. However, both versions work similarly, and the model exported from the multi-backend version can be migrated into the other without further complications.

\subsection{Model architecture}
The final selected model was a convolutional network, which consisted of multiple consecutive convolutional layers, and contained an average pooling layer. A visualisation of the network architecture is shown in \cref{fig:keras_model}. The first convolution layer has consisted of thirty-two filters. The kernel size was $3 \times 3$. The second convolutional layer had sixty-four $3 \times 3$ filters with a stride length of $2 \times 2$. All layers have rectified linear unit (ReLU) as activation function, and the weight matrices were initialised with He uniform initialiser. The only exception is the last dense layer, which uses softmax activation. The presented model was configured to use the Adam \cite{kingmaAdamMethod17} optimizer and categorical cross-entropy as a loss function. 25\% of the training set was held out to serve as validation data. The ANN was trained on the remaining 75\% of the MNIST training set for 2 epochs. The batch size was set to 1024. The trained Keras model was exported to the filesystem to be accessible to the conversion tools. \par
\begin{figure}[htbp]
    \centering
    \includesvg[inkscapelatex=false, height=0.65\textheight]{images/keras_model}
    \caption{The Keras model of a convolutional network used for classification of the MNIST dataset.}
    \label{fig:keras_model}
\end{figure}

\subsection{Conversion with SNN Toolbox}
Conversion of the network with SNN-TB is quite straightforward. There must be created a configuration file, which contains all necessary parameters that must be passed to the \texttt{snntoolbox.bin.run.main()} function of the toolbox. The configuration file can be written with a few simple utility functions of the SNN-TB. The configuration file contains paths to the model and dataset as well as a specification of the used simulator and its parameters, parameters of the simulated spiking neuron cells or plots and variable logs, which should be generated by the toolbox. The SNN-TB then automatically performs the conversion of the network and evaluates it on the given test samples. There is an option to evaluate the ANN input model so the results can be compared instantly. \par
Configuration file specified following values for this execution of SNN-TB: The toolbox was set to evaluate the input model and parse it to SNN-TB internal representation. The activation value in the 99.9 percentile normalised parameters of each layer. Then, integrate-and-fire neurons replaced analogue neurons and by that was the ANN converted into SNN. The SNN was then evaluated on the whole test set of the MNIST dataset. The default simulator of the SNN-TB (INI simulator) was used because it supports most of the potential functionality of the conversion toolbox, so it was not necessary to introduce other limitations to the selected model. Simulation of each sample was configured to run for 120~ms time interval with a time resolution of 0.1~ms. Because the built-in INI simulator supports parallel simulations, the test samples were processed in batches of 500 samples. The simulated spiking neurons had a refractory period and a delay parameters equal to the time resolution of the simulator ($dt=0.1~ms$).\par

\subsection{Conversion with NengoDL Converter}
Several adjustments were needed to execute the selected model of the spiking network in the Nengo simulator. The input samples had to be reformatted to conform with the format which is required by the Nengo simulator. A new dimension was added to the data array to spread the data over the time of the simulation. The input image was flattened into a single dimension. The \texttt{nengo\_dl.Converter} class served for the conversion of the ANN. \par
The converter can be configured to allow a fallback option for features which are not supported by the core Nengo simulator. This option causes that the layers which do not have spiking equivalents are wrapped into NengoDL's \texttt{TensorNode} class. This option makes it possible to use NengoDL to run even more complex network models. However, networks which contain \texttt{TensorNodes} can be run only with NengoDL simulator and cannot be ported to other Nengo environments such as Nengo-core simulator or Nengo backends for hardware platforms. \par
The last layer of the used model was excluded to avoid this silent drop back to a hybrid analogue network before it was used with Nengo. That was necessary because Nengo does not define a conversion of the softmax activation function. Then, NengoDL converter parsed the Keras model into the Nengo model. However, this model still consisted of non-spiking neurons. NengoDL's \texttt{RectifiedLinear} neurons were used because they provided an approximation for the spiking neurons and would be replaced with the \texttt{nengo.SpikingRectifiedLinear} neurons later. This model was used for training during which were performed parameter optimizations. A Nengo \texttt{Probe} object was needed to obtain the output of the last network layer. That output was needed to train the network. The converted model was compiled and trained with the same or equivalent arguments as the original Keras model, that means that Adam optimizer and categorical cross-entropy were specified during the compilation of the model. The model fitted on 75\% of the training set, and the remaining 25\% was used for validation. The training was performed in two epochs, as was with the original Keras model. The retrieved parameters were saved on the filesystem for the testing phase. \par
For the evaluation, the original Keras model was converted with the NengoDL Converter again, but this time, the non-spiking analogue neurons were swapped for spiking leaky integrate-and-fire neurons. A low-pass synaptic smoothing with parameter 0.01 was applied to all the neurons. This operation causes that the spikes in the network are averaged over a short time window. This method helped to remove excess noise from the network output. The input data needed to be repeated once for each timestep of the simulation. \par
Finally, NengoDL simulator ran the prediction of the MNIST test set. Each sample was simulated for 30 timesteps. The parameters exported from the previously created NengoDL model were applied against the spiking network.

\subsection{Comparison of the tools and their results}
Both tools were tested on a subset of 8000 images of the MNIST test set, which have 10000 images in total. The set must have been reduced because the Nengo demanded too much memory. The simulation required more than 25~GB when it was executed on the 10000 samples. Although, the SNN-TB did not have such problems with the whole testing set, the number of tested samples was made equal to compare the results. The original Keras model was also tested on the 8000 samples subset for the same reason. The base Keras ANN achieved an accuracy of 96.55\%. The SNN converted with SNN-TB performed slightly worse, and that is affirmative to results reported by previous works about spiking networks. The NengoDL simulator demonstrated the best accuracy, which is comparable with results of similar network architectures built with Nengo platform. The results can be seen in \cref{tab:MNIST_results}. It should be stated that these results were not validated in any way as the primary purpose of this part of the work was to find out if the tools can be used for conversion of the same base model and how to achieve that.

\begin{table}[htbp]
    \centering
    \begin{tabularx}{\linewidth}{>{\raggedright\arraybackslash}Xc}
    \toprule
        Model & Test accuracy (\%) \\
    \midrule
        Keras base model & 96.55 \\
        SNN in SNN-TB & 94.67 \\
        SNN in NengoDL & 98.45 \\
    \bottomrule
    \end{tabularx}
    \caption{Test accuracies achieved on 8000 samples of the MNIST test set.}
    \label{tab:MNIST_results}
\end{table}

Several findings about the used tools emerged during this experiment. From the software engineering point of view, it seems that the Nengo ecosystem is better designed and might be extended easily. However, it takes time to fully understand it and use its full potential, which is far beyond the illustrated bits. It would probably require a more profound knowledge of the associated methods from NEF and SPA. The SNN conversion toolbox is, on the other hand, well suited for quick trials or familiarization with spiking networks. It offers an uncomplicated way to convert state-of-the-art ANNs to spiking alternatives, which works out of the box. However, it is also probably its sole purpose because it does not offer any interfaces for modifications of its functioning. All potential extensions have to be integrated directly into its source code. \par
Further investigation of the tools should be carried out to evaluate their time and memory requirements because there might be a significant difference as became apparent because of the reason described earlier. That could be achieved by averaging memory consumption and run-time across multiple repetitions of the simulations or by looking into the source code for possible design dissimilarities.